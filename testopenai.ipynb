{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai.api_key= os.getenv('OPEN_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>owned_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>model</td>\n",
       "      <td>1685474247</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dall-e-3</td>\n",
       "      <td>model</td>\n",
       "      <td>1698785189</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text-embedding-3-large</td>\n",
       "      <td>model</td>\n",
       "      <td>1705953180</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4-vision-preview</td>\n",
       "      <td>model</td>\n",
       "      <td>1698894917</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dall-e-2</td>\n",
       "      <td>model</td>\n",
       "      <td>1698798177</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>whisper-1</td>\n",
       "      <td>model</td>\n",
       "      <td>1677532384</td>\n",
       "      <td>openai-internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tts-1-hd-1106</td>\n",
       "      <td>model</td>\n",
       "      <td>1699053533</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tts-1-hd</td>\n",
       "      <td>model</td>\n",
       "      <td>1699046015</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>model</td>\n",
       "      <td>1706048358</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>model</td>\n",
       "      <td>1705948997</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>model</td>\n",
       "      <td>1686588896</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>model</td>\n",
       "      <td>1687882411</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>model</td>\n",
       "      <td>1677610602</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>model</td>\n",
       "      <td>1686587434</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>model</td>\n",
       "      <td>1677649963</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>model</td>\n",
       "      <td>1698959748</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>model</td>\n",
       "      <td>1683758102</td>\n",
       "      <td>openai-internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt-3.5-turbo-instruct-0914</td>\n",
       "      <td>model</td>\n",
       "      <td>1694122472</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tts-1</td>\n",
       "      <td>model</td>\n",
       "      <td>1681940951</td>\n",
       "      <td>openai-internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>davinci-002</td>\n",
       "      <td>model</td>\n",
       "      <td>1692634301</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>model</td>\n",
       "      <td>1698957206</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt-3.5-turbo-instruct</td>\n",
       "      <td>model</td>\n",
       "      <td>1692901427</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>babbage-002</td>\n",
       "      <td>model</td>\n",
       "      <td>1692634615</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tts-1-1106</td>\n",
       "      <td>model</td>\n",
       "      <td>1699053241</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>text-embedding-ada-002</td>\n",
       "      <td>model</td>\n",
       "      <td>1671217299</td>\n",
       "      <td>openai-internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gpt-4-turbo-preview</td>\n",
       "      <td>model</td>\n",
       "      <td>1706037777</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>model</td>\n",
       "      <td>1706037612</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id object     created         owned_by\n",
       "0        gpt-3.5-turbo-16k-0613  model  1685474247           openai\n",
       "1                      dall-e-3  model  1698785189           system\n",
       "2        text-embedding-3-large  model  1705953180           system\n",
       "3          gpt-4-vision-preview  model  1698894917           system\n",
       "4                      dall-e-2  model  1698798177           system\n",
       "5                     whisper-1  model  1677532384  openai-internal\n",
       "6                 tts-1-hd-1106  model  1699053533           system\n",
       "7                      tts-1-hd  model  1699046015           system\n",
       "8            gpt-3.5-turbo-0125  model  1706048358           system\n",
       "9        text-embedding-3-small  model  1705948997           system\n",
       "10                   gpt-4-0613  model  1686588896           openai\n",
       "11                        gpt-4  model  1687882411           openai\n",
       "12                gpt-3.5-turbo  model  1677610602           openai\n",
       "13           gpt-3.5-turbo-0613  model  1686587434           openai\n",
       "14           gpt-3.5-turbo-0301  model  1677649963           openai\n",
       "15           gpt-3.5-turbo-1106  model  1698959748           system\n",
       "16            gpt-3.5-turbo-16k  model  1683758102  openai-internal\n",
       "17  gpt-3.5-turbo-instruct-0914  model  1694122472           system\n",
       "18                        tts-1  model  1681940951  openai-internal\n",
       "19                  davinci-002  model  1692634301           system\n",
       "20           gpt-4-1106-preview  model  1698957206           system\n",
       "21       gpt-3.5-turbo-instruct  model  1692901427           system\n",
       "22                  babbage-002  model  1692634615           system\n",
       "23                   tts-1-1106  model  1699053241           system\n",
       "24       text-embedding-ada-002  model  1671217299  openai-internal\n",
       "25          gpt-4-turbo-preview  model  1706037777           system\n",
       "26           gpt-4-0125-preview  model  1706037612           system"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.DataFrame(openai.Model.list()['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-90gUEth1iKkkbrNLW6O04Nw6HVLB3 at 0x7fadf80620b0> JSON: {\n",
       "  \"id\": \"cmpl-90gUEth1iKkkbrNLW6O04Nw6HVLB3\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1709950346,\n",
       "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\nBaghdad\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 6,\n",
       "    \"completion_tokens\": 4,\n",
       "    \"total_tokens\": 10\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "    model='gpt-3.5-turbo-instruct',\n",
    "    prompt='what is the capital of Iraq',\n",
    "    max_tokens= 10,\n",
    ")\n",
    "\n",
    "response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Imagine you have a magic pencil that can draw pictures all by itself. At first, it doesn't know how\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    model='gpt-3.5-turbo-instruct',\n",
    "    prompt='Act like ai assistant and explain machine learning to a 5 years old in 3 diffrient way',\n",
    "    max_tokens= 25,\n",
    "    temperature= 0.6,\n",
    "    \n",
    ")\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Paris, France\n",
      "2. New York City, United States\n",
      "3. Tokyo, Japan\n",
      "4. London\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = openai.Completion.create(\n",
    "        model='gpt-3.5-turbo-instruct',\n",
    "        prompt='Top 4 famous cities in the world',\n",
    "        max_tokens= 25,\n",
    "        temperature= 0.6,\n",
    "        n= 10\n",
    "    )\n",
    "    print(response.choices[0].text.strip())\n",
    "except openai.error.RateLimitError as e:\n",
    "    print(\"Rate limit exceeded. Please try again later or check your OpenAI dashboard for usage details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Paris, France\n",
      "2. New York City, United States\n",
      "3. Tokyo, Japan\n",
      "4. London\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-90gX2gb3eg9uolHMRkpRkgUjHWpVD at 0x7fadf8df7590> JSON: {\n",
       "  \"id\": \"cmpl-90gX2gb3eg9uolHMRkpRkgUjHWpVD\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1709950520,\n",
       "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"0.9968984121704102 negative\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 26,\n",
       "    \"completion_tokens\": 9,\n",
       "    \"total_tokens\": 35\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= openai.Completion.create(\n",
    "        model='gpt-3.5-turbo-instruct',\n",
    "        prompt= ''' Act as an AI model to detect postive or negative tweets:\n",
    "        This person is bad and he is biased towards negative sentiments\n",
    "''',\n",
    "        max_tokens= 15,\n",
    "        temperature= 1,\n",
    "        n= 1\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9968984121704102 negative\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-90gYHM35zTgjZFOYjGNDa9BhbxGSe at 0x7fadf8deebf0> JSON: {\n",
       "  \"id\": \"cmpl-90gYHM35zTgjZFOYjGNDa9BhbxGSe\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1709950597,\n",
       "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"        \\u2192 \\\"Bonjour, comment \\u00e7a va?\\\"\\n    \\\\end{center}\\n\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"length\"\n",
       "    },\n",
       "    {\n",
       "      \"text\": \"        \\\"\\\"\\\"\\n\\n    return \\\"Salut Comment vas-tu?\\\"\",\n",
       "      \"index\": 1,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    },\n",
       "    {\n",
       "      \"text\": \"\\nBonjour, Comment vas-tu?\",\n",
       "      \"index\": 2,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    },\n",
       "    {\n",
       "      \"text\": \"       \\nBonjour comment vas-tu ?\",\n",
       "      \"index\": 3,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    },\n",
       "    {\n",
       "      \"text\": \"\\n\\nHello Comment allez-vous ?\\n\",\n",
       "      \"index\": 4,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 18,\n",
       "    \"completion_tokens\": 52,\n",
       "    \"total_tokens\": 70\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= openai.Completion.create(\n",
    "        model='gpt-3.5-turbo-instruct',\n",
    "        prompt= ''' Act as an AI model to translate text to french:\n",
    "        \"Hello How are you?\"\n",
    "''',\n",
    "        max_tokens= 15,\n",
    "        temperature= 1,\n",
    "        n= 5\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        → \"Bonjour, comment ça va?\"\n",
      "    \\end{center}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-90gYoO9mPF96e8fGiyQKlRSdpNIGr at 0x7fadf8df79b0> JSON: {\n",
       "  \"id\": \"chatcmpl-90gYoO9mPF96e8fGiyQKlRSdpNIGr\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1709950630,\n",
       "  \"model\": \"gpt-3.5-turbo-0125\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"You mentioned earlier that you are 37 years old.\"\n",
       "      },\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 44,\n",
       "    \"completion_tokens\": 11,\n",
       "    \"total_tokens\": 55\n",
       "  },\n",
       "  \"system_fingerprint\": \"fp_2b778c6b35\"\n",
       "}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ChatCompletion APT\n",
    "\n",
    "openai.ChatCompletion.create(\n",
    "    model= 'gpt-3.5-turbo',\n",
    "    messages = [{'role': 'system', 'content':'Act as an AI Assistant'},\n",
    "                {'role': 'user', 'content':'Hello How are you'},\n",
    "                {'role': 'user', 'content':'My age is 37 and i am a data scientist'},\n",
    "                {'role': 'user', 'content':'What is my age?'}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion= openai.ChatCompletion.create(\n",
    "    model= 'gpt-3.5-turbo',\n",
    "    messages= [\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant which informs about temerature\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hey there\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Hello! How can I assist you today?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "import requests\n",
    "def get_current_weather(location):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "\n",
    "    url = \"https://ai-weather-by-meteosource.p.rapidapi.com/find_places\"\n",
    "\n",
    "    querystring = {\"text\":location}\n",
    "\n",
    "    headers = {\n",
    "      \"X-RapidAPI-Key\": \"6ffc46588amsh28f4dc3b6943c87p197ec4jsnc0961371aab8\",\n",
    "      \"X-RapidAPI-Host\": \"ai-weather-by-meteosource.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "    print(response.json())\n",
    "  \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'San Jose', 'place_id': 'san-jose', 'adm_area1': 'California', 'adm_area2': 'Santa Clara County', 'country': 'United States of America', 'lat': '37.33939N', 'lon': '121.89496W', 'timezone': 'America/Los_Angeles', 'type': 'settlement'}, {'name': 'San José', 'place_id': 'san-jose-3621849', 'adm_area1': 'San José', 'adm_area2': 'San José', 'country': 'Republic of Costa Rica', 'lat': '9.93333N', 'lon': '84.08333W', 'timezone': 'America/Costa_Rica', 'type': 'settlement'}, {'name': 'San Jose', 'place_id': 'san-jose-1689510', 'adm_area1': 'Mimaropa', 'adm_area2': 'Occidental Mindoro', 'country': 'Philippines', 'lat': '12.35275N', 'lon': '121.06761E', 'timezone': 'Asia/Manila', 'type': 'settlement'}, {'name': 'Provincia de San José', 'place_id': 'provincia-de-san-jose', 'adm_area1': 'San José', 'adm_area2': None, 'country': 'Republic of Costa Rica', 'lat': '9.66667N', 'lon': '84.0W', 'timezone': 'America/Costa_Rica', 'type': 'administrative_area'}, {'name': 'San Jose City', 'place_id': 'san-jose-city', 'adm_area1': 'Central Luzon', 'adm_area2': 'Province of Nueva Ecija', 'country': 'Philippines', 'lat': '15.8N', 'lon': '120.98333E', 'timezone': 'Asia/Manila', 'type': 'administrative_area'}, {'name': 'Departamento de San José', 'place_id': 'departamento-de-san-jose', 'adm_area1': 'San José', 'adm_area2': None, 'country': 'Oriental Republic of Uruguay', 'lat': '34.25S', 'lon': '56.75W', 'timezone': 'America/Montevideo', 'type': 'administrative_area'}, {'name': 'Cúcuta', 'place_id': 'cucuta', 'adm_area1': 'Norte de Santander', 'adm_area2': 'Cúcuta', 'country': 'Republic of Colombia', 'lat': '7.89391N', 'lon': '72.50782W', 'timezone': 'America/Bogota', 'type': 'settlement'}, {'name': 'São José dos Campos', 'place_id': 'sao-jose-dos-campos', 'adm_area1': 'São Paulo', 'adm_area2': 'São José dos Campos', 'country': 'Brazil', 'lat': '23.17944S', 'lon': '45.88694W', 'timezone': 'America/Sao_Paulo', 'type': 'settlement'}, {'name': 'São José do Rio Preto', 'place_id': 'sao-jose-do-rio-preto', 'adm_area1': 'São Paulo', 'adm_area2': 'São José do Rio Preto', 'country': 'Brazil', 'lat': '20.81972S', 'lon': '49.37944W', 'timezone': 'America/Sao_Paulo', 'type': 'settlement'}, {'name': 'San Jose del Monte', 'place_id': 'san-jose-del-monte', 'adm_area1': 'Central Luzon', 'adm_area2': 'Province of Bulacan', 'country': 'Philippines', 'lat': '14.81389N', 'lon': '121.04528E', 'timezone': 'Asia/Manila', 'type': 'settlement'}]\n"
     ]
    }
   ],
   "source": [
    "response=get_current_weather('San Jose')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'San Jose',\n",
       "  'place_id': 'san-jose',\n",
       "  'adm_area1': 'California',\n",
       "  'adm_area2': 'Santa Clara County',\n",
       "  'country': 'United States of America',\n",
       "  'lat': '37.33939N',\n",
       "  'lon': '121.89496W',\n",
       "  'timezone': 'America/Los_Angeles',\n",
       "  'type': 'settlement'},\n",
       " {'name': 'San José',\n",
       "  'place_id': 'san-jose-3621849',\n",
       "  'adm_area1': 'San José',\n",
       "  'adm_area2': 'San José',\n",
       "  'country': 'Republic of Costa Rica',\n",
       "  'lat': '9.93333N',\n",
       "  'lon': '84.08333W',\n",
       "  'timezone': 'America/Costa_Rica',\n",
       "  'type': 'settlement'},\n",
       " {'name': 'San Jose',\n",
       "  'place_id': 'san-jose-1689510',\n",
       "  'adm_area1': 'Mimaropa',\n",
       "  'adm_area2': 'Occidental Mindoro',\n",
       "  'country': 'Philippines',\n",
       "  'lat': '12.35275N',\n",
       "  'lon': '121.06761E',\n",
       "  'timezone': 'Asia/Manila',\n",
       "  'type': 'settlement'},\n",
       " {'name': 'Provincia de San José',\n",
       "  'place_id': 'provincia-de-san-jose',\n",
       "  'adm_area1': 'San José',\n",
       "  'adm_area2': None,\n",
       "  'country': 'Republic of Costa Rica',\n",
       "  'lat': '9.66667N',\n",
       "  'lon': '84.0W',\n",
       "  'timezone': 'America/Costa_Rica',\n",
       "  'type': 'administrative_area'},\n",
       " {'name': 'San Jose City',\n",
       "  'place_id': 'san-jose-city',\n",
       "  'adm_area1': 'Central Luzon',\n",
       "  'adm_area2': 'Province of Nueva Ecija',\n",
       "  'country': 'Philippines',\n",
       "  'lat': '15.8N',\n",
       "  'lon': '120.98333E',\n",
       "  'timezone': 'Asia/Manila',\n",
       "  'type': 'administrative_area'},\n",
       " {'name': 'Departamento de San José',\n",
       "  'place_id': 'departamento-de-san-jose',\n",
       "  'adm_area1': 'San José',\n",
       "  'adm_area2': None,\n",
       "  'country': 'Oriental Republic of Uruguay',\n",
       "  'lat': '34.25S',\n",
       "  'lon': '56.75W',\n",
       "  'timezone': 'America/Montevideo',\n",
       "  'type': 'administrative_area'},\n",
       " {'name': 'Cúcuta',\n",
       "  'place_id': 'cucuta',\n",
       "  'adm_area1': 'Norte de Santander',\n",
       "  'adm_area2': 'Cúcuta',\n",
       "  'country': 'Republic of Colombia',\n",
       "  'lat': '7.89391N',\n",
       "  'lon': '72.50782W',\n",
       "  'timezone': 'America/Bogota',\n",
       "  'type': 'settlement'},\n",
       " {'name': 'São José dos Campos',\n",
       "  'place_id': 'sao-jose-dos-campos',\n",
       "  'adm_area1': 'São Paulo',\n",
       "  'adm_area2': 'São José dos Campos',\n",
       "  'country': 'Brazil',\n",
       "  'lat': '23.17944S',\n",
       "  'lon': '45.88694W',\n",
       "  'timezone': 'America/Sao_Paulo',\n",
       "  'type': 'settlement'},\n",
       " {'name': 'São José do Rio Preto',\n",
       "  'place_id': 'sao-jose-do-rio-preto',\n",
       "  'adm_area1': 'São Paulo',\n",
       "  'adm_area2': 'São José do Rio Preto',\n",
       "  'country': 'Brazil',\n",
       "  'lat': '20.81972S',\n",
       "  'lon': '49.37944W',\n",
       "  'timezone': 'America/Sao_Paulo',\n",
       "  'type': 'settlement'},\n",
       " {'name': 'San Jose del Monte',\n",
       "  'place_id': 'san-jose-del-monte',\n",
       "  'adm_area1': 'Central Luzon',\n",
       "  'adm_area2': 'Province of Bulacan',\n",
       "  'country': 'Philippines',\n",
       "  'lat': '14.81389N',\n",
       "  'lon': '121.04528E',\n",
       "  'timezone': 'Asia/Manila',\n",
       "  'type': 'settlement'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_current_weather',\n",
       "  'description': 'Get the current weather in a given location',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'location': {'type': 'string',\n",
       "     'description': 'The city and state, e.g. San Francisco, CA'}},\n",
       "   'required': ['location']}}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message=\"Hi There\"\n",
    "messages=[]\n",
    "messages.append({\"role\": \"user\", \"content\":user_message})\n",
    "completion=openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=\n",
    "       messages\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Hello! How can I assist you today?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Hi There'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message=\"What is the temperature of San Jose, CA\"\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "completion=openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Hi There'},\n",
       " {'role': 'user', 'content': 'What is the temperature of San Jose, CA'},\n",
       " {'role': 'user', 'content': 'What is the temperature of San Jose, CA'},\n",
       " {'role': 'user', 'content': 'What is the temperature of San Jose, CA'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-916Wmxdm8ibcxoIFsijBaF62D2gHj at 0x7fadf8e00290> JSON: {\n",
       "  \"id\": \"chatcmpl-916Wmxdm8ibcxoIFsijBaF62D2gHj\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1710050448,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": null,\n",
       "        \"function_call\": {\n",
       "          \"name\": \"get_current_weather\",\n",
       "          \"arguments\": \"{\\n  \\\"location\\\": \\\"San Jose, CA\\\"\\n}\"\n",
       "        }\n",
       "      },\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"function_call\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 91,\n",
       "    \"completion_tokens\": 19,\n",
       "    \"total_tokens\": 110\n",
       "  },\n",
       "  \"system_fingerprint\": null\n",
       "}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"name\": \"get_current_weather\",\n",
      "    \"arguments\": \"{\\n  \\\"location\\\": \\\"San Jose, CA\\\"\\n}\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x7fadf8e00830> JSON: {\n",
       "  \"role\": \"assistant\",\n",
       "  \"content\": null,\n",
       "  \"function_call\": {\n",
       "    \"name\": \"get_current_weather\",\n",
       "    \"arguments\": \"{\\n  \\\"location\\\": \\\"San Jose, CA\\\"\\n}\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= completion.choices[0].message\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_weather'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_name= response['function_call']['name']\n",
    "function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'San Jose, CA'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "location= eval(response['function_call']['arguments'])['location']\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: send the info on the function call and function response to GPT\n",
    "messages.append(response)  # extend conversation with assistant's reply\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"function\",\n",
    "        \"name\": function_name,\n",
    "        \"content\": location,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Hi There'},\n",
       " {'role': 'user', 'content': 'What is the temperature of San Jose, CA'},\n",
       " {'role': 'user', 'content': 'What is the temperature of San Jose, CA'},\n",
       " {'role': 'user', 'content': 'What is the temperature of San Jose, CA'},\n",
       " <OpenAIObject at 0x7fadf8e00830> JSON: {\n",
       "   \"role\": \"assistant\",\n",
       "   \"content\": null,\n",
       "   \"function_call\": {\n",
       "     \"name\": \"get_current_weather\",\n",
       "     \"arguments\": \"{\\n  \\\"location\\\": \\\"San Jose, CA\\\"\\n}\"\n",
       "   }\n",
       " },\n",
       " {'role': 'function',\n",
       "  'name': 'get_current_weather',\n",
       "  'content': 'San Jose, CA'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend conversation with function response\n",
    "second_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions\n",
    ")  # get a new response from GPT where it can see the function response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"The current temperature in San Jose, CA is 70\\u00b0F.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-916ihzxTyAJKPPawFi1Wb4qqbkq7e at 0x7fadf8e47a10> JSON: {\n",
       "  \"id\": \"chatcmpl-916ihzxTyAJKPPawFi1Wb4qqbkq7e\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1710051187,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"The current temperature in San Jose, CA is 70\\u00b0F.\"\n",
       "      },\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 136,\n",
       "    \"completion_tokens\": 14,\n",
       "    \"total_tokens\": 150\n",
       "  },\n",
       "  \"system_fingerprint\": null\n",
       "}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
